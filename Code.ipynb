{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device.type == 'cuda':\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/X.csv')\n",
    "Y = pd.read_csv('data/Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ram</th>\n",
       "      <th>#ofcores</th>\n",
       "      <th>utilization_mean</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>IT_dur_ms</th>\n",
       "      <th>Anti-Virus_dur_ms</th>\n",
       "      <th>Communication_dur_ms</th>\n",
       "      <th>Game_dur_ms</th>\n",
       "      <th>Installer/Updater_dur_ms</th>\n",
       "      <th>Internet_dur_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>cpu_family_Core i5</th>\n",
       "      <th>cpu_family_Core i7</th>\n",
       "      <th>cpu_family_Core i9</th>\n",
       "      <th>cpu_family_Core2</th>\n",
       "      <th>cpu_family_Pentium/Celeron</th>\n",
       "      <th>cpu_family_Xeon</th>\n",
       "      <th>discretegraphics_N</th>\n",
       "      <th>discretegraphics_Y</th>\n",
       "      <th>vpro_enabled_N</th>\n",
       "      <th>vpro_enabled_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.812885</td>\n",
       "      <td>39.290535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.001764</td>\n",
       "      <td>41.529495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.331238</td>\n",
       "      <td>54.387505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.096786</td>\n",
       "      <td>58.178394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.435486</td>\n",
       "      <td>33.730610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ram  #ofcores  utilization_mean  temp_mean  IT_dur_ms  Anti-Virus_dur_ms  \\\n",
       "0   8.0       2.0         41.812885  39.290535        0.0                0.0   \n",
       "1   8.0       2.0         23.001764  41.529495        0.0                0.0   \n",
       "2   6.0       2.0         42.331238  54.387505        0.0                0.0   \n",
       "3  12.0       4.0         45.096786  58.178394        0.0                0.0   \n",
       "4   8.0       2.0         45.435486  33.730610        0.0                0.0   \n",
       "\n",
       "   Communication_dur_ms  Game_dur_ms  Installer/Updater_dur_ms  \\\n",
       "0                   0.0          0.0                       0.0   \n",
       "1                   0.0          0.0                       0.0   \n",
       "2                   0.0          0.0                       0.0   \n",
       "3                   0.0          0.0                       0.0   \n",
       "4                   0.0          0.0                       0.0   \n",
       "\n",
       "   Internet_dur_ms  ...  cpu_family_Core i5  cpu_family_Core i7  \\\n",
       "0              0.0  ...                   1                   0   \n",
       "1              0.0  ...                   1                   0   \n",
       "2              0.0  ...                   1                   0   \n",
       "3              0.0  ...                   1                   0   \n",
       "4              0.0  ...                   0                   0   \n",
       "\n",
       "   cpu_family_Core i9  cpu_family_Core2  cpu_family_Pentium/Celeron  \\\n",
       "0                   0                 0                           0   \n",
       "1                   0                 0                           0   \n",
       "2                   0                 0                           0   \n",
       "3                   0                 0                           0   \n",
       "4                   0                 0                           0   \n",
       "\n",
       "   cpu_family_Xeon  discretegraphics_N  discretegraphics_Y  vpro_enabled_N  \\\n",
       "0                0                   1                   0               1   \n",
       "1                0                   1                   0               1   \n",
       "2                0                   0                   1               1   \n",
       "3                0                   1                   0               1   \n",
       "4                0                   1                   0               1   \n",
       "\n",
       "   vpro_enabled_Y  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 461 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12976</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12977 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       persona\n",
       "0            1\n",
       "1            0\n",
       "2            0\n",
       "3            1\n",
       "4            2\n",
       "...        ...\n",
       "12972        1\n",
       "12973        0\n",
       "12974        0\n",
       "12975        1\n",
       "12976        0\n",
       "\n",
       "[12977 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>persona</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     persona\n",
       "0          1\n",
       "1          0\n",
       "4          2\n",
       "156        3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.drop_duplicates() # there are 4 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>I. Classification using MLP:<ins>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Pre-processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ram</th>\n",
       "      <th>#ofcores</th>\n",
       "      <th>utilization_mean</th>\n",
       "      <th>temp_mean</th>\n",
       "      <th>IT_dur_ms</th>\n",
       "      <th>Anti-Virus_dur_ms</th>\n",
       "      <th>Communication_dur_ms</th>\n",
       "      <th>Game_dur_ms</th>\n",
       "      <th>Installer/Updater_dur_ms</th>\n",
       "      <th>Internet_dur_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>cpu_family_Core i7</th>\n",
       "      <th>cpu_family_Core i9</th>\n",
       "      <th>cpu_family_Core2</th>\n",
       "      <th>cpu_family_Pentium/Celeron</th>\n",
       "      <th>cpu_family_Xeon</th>\n",
       "      <th>discretegraphics_N</th>\n",
       "      <th>discretegraphics_Y</th>\n",
       "      <th>vpro_enabled_N</th>\n",
       "      <th>vpro_enabled_Y</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.812885</td>\n",
       "      <td>39.290535</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.001764</td>\n",
       "      <td>41.529495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.331238</td>\n",
       "      <td>54.387505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>45.096786</td>\n",
       "      <td>58.178394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45.435486</td>\n",
       "      <td>33.730610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 462 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ram  #ofcores  utilization_mean  temp_mean  IT_dur_ms  Anti-Virus_dur_ms  \\\n",
       "0   8.0       2.0         41.812885  39.290535        0.0                0.0   \n",
       "1   8.0       2.0         23.001764  41.529495        0.0                0.0   \n",
       "2   6.0       2.0         42.331238  54.387505        0.0                0.0   \n",
       "3  12.0       4.0         45.096786  58.178394        0.0                0.0   \n",
       "4   8.0       2.0         45.435486  33.730610        0.0                0.0   \n",
       "\n",
       "   Communication_dur_ms  Game_dur_ms  Installer/Updater_dur_ms  \\\n",
       "0                   0.0          0.0                       0.0   \n",
       "1                   0.0          0.0                       0.0   \n",
       "2                   0.0          0.0                       0.0   \n",
       "3                   0.0          0.0                       0.0   \n",
       "4                   0.0          0.0                       0.0   \n",
       "\n",
       "   Internet_dur_ms  ...  cpu_family_Core i7  cpu_family_Core i9  \\\n",
       "0              0.0  ...                   0                   0   \n",
       "1              0.0  ...                   0                   0   \n",
       "2              0.0  ...                   0                   0   \n",
       "3              0.0  ...                   0                   0   \n",
       "4              0.0  ...                   0                   0   \n",
       "\n",
       "   cpu_family_Core2  cpu_family_Pentium/Celeron  cpu_family_Xeon  \\\n",
       "0                 0                           0                0   \n",
       "1                 0                           0                0   \n",
       "2                 0                           0                0   \n",
       "3                 0                           0                0   \n",
       "4                 0                           0                0   \n",
       "\n",
       "   discretegraphics_N  discretegraphics_Y  vpro_enabled_N  vpro_enabled_Y  Y  \n",
       "0                   1                   0               1               0  1  \n",
       "1                   1                   0               1               0  0  \n",
       "2                   0                   1               1               0  0  \n",
       "3                   1                   0               1               0  1  \n",
       "4                   1                   0               1               0  2  \n",
       "\n",
       "[5 rows x 462 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate X & Y to make random splitting\n",
    "df = X\n",
    "df['Y'] = Y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "df_train, df_test = train_test_split(df, train_size=0.8, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X -- event features\n",
    "X_train = torch.tensor(df_train.values).to(device)\n",
    "X_test = torch.tensor(df_test.values).to(device)\n",
    "\n",
    "# Y -- label\n",
    "Y_train = torch.tensor(df_train[['Y']].values).to(device)\n",
    "Y_test = torch.tensor(df_test[['Y']].values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable features is: 462\n"
     ]
    }
   ],
   "source": [
    "num_features = X_train.shape[1]\n",
    "print(\"Number of trainable features is:\", num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Dataset_train(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x = X_train\n",
    "        self.y = Y_train\n",
    "        \n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "class Dataset_test(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.x = X_test\n",
    "        self.y = Y_test\n",
    "        \n",
    "        self.n_samples = self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset_train = Dataset_train()\n",
    "dataset_test = Dataset_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this helps create a data loader which iterates over tuples of target/labels with specfied batch size\n",
    "# everytime the next function is called we receive the next batch sample & target until we cover all the data\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=2, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset_train, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 8.0000,  2.0000, 47.2251, 45.2511,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [16.0000,  4.0000, 17.3683, 51.0855,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  1.0000,  1.0000,  0.0000,  0.0000]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[1],\n",
       "         [0]])]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# that's how you claim a batch to feed to the model\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 8.0000,  2.0000, 38.2091, 53.1600,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "         [12.0000,  2.0000, 27.5696, 47.1860,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  1.0000,\n",
       "           0.0000,  0.0000,  1.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000]],\n",
       "        dtype=torch.float64),\n",
       " tensor([[1],\n",
       "         [0]])]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Model of the MLP classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, width, n_inputs):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.width = width\n",
    "    \n",
    "        # input layer\n",
    "        self.input = nn.Linear(n_inputs, width)\n",
    "    \n",
    "        # hidden layers\n",
    "        self.h1 = nn.Linear(in_features=width, out_features=width)\n",
    "        self.h2 = nn.Linear(in_features=width, out_features=width)\n",
    "    \n",
    "        # output layer\n",
    "        self.output = nn.Linear(width, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "    \n",
    "        # input layer\n",
    "        x = F.relu(self.input(x))\n",
    "    \n",
    "        # hidden layers\n",
    "        x = F.relu(self.h1(x))\n",
    "        x = F.relu(self.h2(x))\n",
    "        \n",
    "        # output layer\n",
    "        x = F.softmax(self.output(x), dim=1)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Training of the MLP classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-125-9328d2172f67>:19: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm(train_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72ae9430041403ba1223171ab5277cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=5191.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.0000, 1.0000, 0.0000, 0.0000],\n",
      "        [0.2357, 0.2667, 0.2461, 0.2515]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[2],\n",
      "        [2]])\n",
      "tensor(1.5670, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# this is a quick check that the model accepts the input and spits an output of a correct class\n",
    "\n",
    "# create the network\n",
    "network = Classifier(800, n_inputs=num_features).to(device)\n",
    "\n",
    "# choose the criterion for the loss function (for multiclassification we usually use Cross Entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# create the optimiser (based on Gradient Descent)\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.01)\n",
    "\n",
    "# keep track of the losses\n",
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "avg_losses = []               ######## for plotting we need losses per epoch\n",
    "avg_losses_test = []\n",
    "\n",
    "for batch in tqdm(train_loader):\n",
    "\n",
    "    X,Y = batch\n",
    "\n",
    "    # forwardprop\n",
    "    preds = network(X.float())\n",
    "    loss = criterion(preds,Y.reshape(-1))\n",
    "\n",
    "    break\n",
    "    \n",
    "print(preds)\n",
    "print(Y)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import time\n",
    "\n",
    "def normal_training(epochs=20, batch_size = 32, learning_rate=0.01):        \n",
    "\n",
    "    # create the network\n",
    "    network = Classifier(1000, n_inputs=num_features).to(device)\n",
    "\n",
    "    # choose the criterion\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # create the optimiser\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # keep track of the losses\n",
    "    losses_train = []\n",
    "    losses_test = []\n",
    "\n",
    "    avg_losses_train = []               ######## for plotting we need losses per epoch\n",
    "    avg_losses_test = []\n",
    "\n",
    "    # create data loaders to begin the training\n",
    "    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset_test, batch_size)\n",
    "\n",
    "    # start a timer\n",
    "    begt = time.time()\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        \n",
    "        # to evaluate accuracies while training\n",
    "        correct_preds_train = 0\n",
    "        correct_preds_test = 0\n",
    "        \n",
    "        for batch in tqdm(train_loader):\n",
    "            \n",
    "            X,Y = batch\n",
    "\n",
    "            # forwardprop\n",
    "            preds = network(X.float())\n",
    "            loss_train = criterion(preds,Y.reshape(-1))\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()                    ######## To avoid accumulating the gradients\n",
    "            loss_train.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            losses_train.append(loss_train.to('cpu').detach().numpy())\n",
    "\n",
    "            # feedback to assess training accuracy\n",
    "            correct_preds_train += (preds.argmax(axis=1)==Y.reshape(-1)).sum().item()\n",
    "                        \n",
    "        train_acc = correct_preds_train/(len(train_loader)*batch_size)\n",
    "\n",
    "        # check model performance on test data\n",
    "        with torch.no_grad():                  ### important to specefy that you don't need pytorch to calculate gradients\n",
    "            for batch in test_loader:\n",
    "\n",
    "                X,Y = batch\n",
    "\n",
    "                # forwardprop\n",
    "                preds = network(X.float())\n",
    "                loss_test = criterion(preds,Y.reshape(-1)) \n",
    "                losses_test.append(loss_test.to('cpu').detach().numpy())\n",
    "            \n",
    "                # feedback to assess testing accuracy\n",
    "                correct_preds_test += (preds.argmax(axis=1)==Y.reshape(-1)).sum().item()\n",
    "\n",
    "        test_acc = correct_preds_test/(len(test_loader)*batch_size)\n",
    "\n",
    "        # calculate loss averages to use them in plots\n",
    "        avg_losses_train.append(np.mean(losses_train)) \n",
    "        avg_losses_test.append(np.mean(losses_test))\n",
    "\n",
    "        print(\"Epoch:\", epoch+1, \" - train_loss:\", avg_losses_train[epoch], \" - Train accuracy: \", round(train_acc*100,2),  \" - Test accuracy: \", round(test_acc*100,2))\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(range(len(avg_losses_train)), avg_losses_train, label='train loss')\n",
    "    ax.plot(range(len(avg_losses_test)), avg_losses_test, label='test loss')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Classifier loss')\n",
    "    ax.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Training time:\", round(((time.time()-begt)/60),2),\"min\" )\n",
    "\n",
    "    return network, train_acc, test_acc, avg_losses_train, avg_losses_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-140-61f8f61a33f8>:29: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for epoch in tqdm(range(epochs)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e67453946d4d0fae4f0f96b83ad043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-140-61f8f61a33f8>:35: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for batch in tqdm(train_loader):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc7bcef6f9e46b5a0fc0dbfc08f2a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1  - train_loss: 1.0984206  - Train accuracy:  64.43  - Test accuracy:  63.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8badd05026614fa192dbef804bf1e925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2  - train_loss: 1.0982484  - Train accuracy:  64.43  - Test accuracy:  63.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d9df3bd41104364a54f04d579df85d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=325.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3  - train_loss: 1.0981909  - Train accuracy:  64.43  - Test accuracy:  63.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0.31 min\n"
     ]
    }
   ],
   "source": [
    "clf, train_acc, test_acc, train_loss, test_loss = normal_training(epochs=3, batch_size = 32, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
